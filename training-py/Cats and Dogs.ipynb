{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zszC-mkM5CRl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib nbagg\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "for device in sess.list_devices():\n",
    "    print(device.name)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning) # Hide corrupt files from log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ah4xnQqsqQ96"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uz9JkFTLsJvk"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eECOM_NWnApT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Download dataset from https://www.microsoft.com/en-us/download/details.aspx?id=54765",
    "\n",
    "print(\"Decompressing Data...\")\n",
    "!unzip -u kagglecatsanddogs_3367a.zip\n",
    "print(\"Deleting Extra or Corrupt files\")\n",
    "!rm -v \"MSR-LA - 3467.docx\" \"readme[1].txt\" \"PetImages/Cat/666.jpg\" \"PetImages/Dog/11702.jpg\"\n",
    "!du -hd1 PetImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WiXSU3PWn7NI"
   },
   "source": [
    "# data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeaFYu_Nnwih"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "image_data_generator = image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    width_shift_range=0.2, height_shift_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True, vertical_flip=False\n",
    ")\n",
    "\n",
    "options = {\n",
    "    \"directory\": './PetImages',\n",
    "    \"target_size\": (100, 100),\n",
    "    \"batch_size\": 32,\n",
    "    \"class_mode\": 'binary'\n",
    "}\n",
    "\n",
    "\n",
    "training_data = image_data_generator.flow_from_directory(\n",
    "    **options,\n",
    "    subset='training')\n",
    "\n",
    "validation_data = image_data_generator.flow_from_directory(\n",
    "    **options,\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVY5k7sHn-qb"
   },
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOcmWkIkoBBQ"
   },
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional Layers\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(100, 100, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense Layers TODO: How many dense layers are needed? How many neurons per layer?\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Dropout helps prevent over fitting\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "# Sigmoid scales data for a binary output\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(amsgrad=True),  # TODO: Best optimizer?\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47VG433PoCn0"
   },
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6-_hTFnoEVp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from model import model\n",
    "# from data import training_data, validation_data\n",
    "from keras import callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class PerfGraph(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.y_val = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.x += [epoch]\n",
    "        self.y += [logs['acc']]\n",
    "        self.y_val += [logs['val_acc']]\n",
    "        \n",
    "    def on_train_end(self, logs={}):\n",
    "        plt.plot(self.x, self.y, '-.g')#, 'Training Accuracy')\n",
    "        plt.plot(self.x, self.y_val, '-b')#, 'Validation Accuracy')\n",
    "        plt.show()\n",
    "\n",
    "batch_size = 256\n",
    "total_training_images = 20000\n",
    "total_validation_images = 4998\n",
    "\n",
    "filepath = \"AMSGrad-{epoch:03d}-{val_acc:.3f}.hdf5\"\n",
    "callbacks = [\n",
    "    PerfGraph(),\n",
    "    callbacks.ModelCheckpoint(filepath, monitor='val_acc', save_best_only=False, save_weights_only=True),\n",
    "    callbacks.TerminateOnNaN(),\n",
    "    callbacks.ReduceLROnPlateau()\n",
    "#     callbacks.EarlyStopping(min_delta=0.025 ,patience=2, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "model.fit_generator(\n",
    "    training_data,\n",
    "    steps_per_epoch=total_training_images // batch_size,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=total_validation_images // batch_size,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save_weights('final weights.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lb9FJxPotN07"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from skimage import transform\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model.load_weights('AMSGrad-0.9.hdf5')\n",
    "\n",
    "num_images = 10000\n",
    "\n",
    "def predict_path(model, path):\n",
    "    try:\n",
    "        img = plt.imread(path)\n",
    "        img = transform.resize(img, (100, 100))\n",
    "        img.shape = (1, 100, 100, 3)\n",
    "    except ValueError:\n",
    "        return 0.5\n",
    "    except FileNotFoundError:\n",
    "        return 0.5\n",
    "    \n",
    "    generator = image_data_generator = image.ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True\n",
    "    ).flow(img, [0])\n",
    "\n",
    "    return model.predict_generator(generator, steps=1)[0][0]\n",
    "\n",
    "def predict_model(model):\n",
    "    dog_total = 0\n",
    "    cat_total = 0\n",
    "\n",
    "    for i in range(num_images):\n",
    "        print('\\r', end='')\n",
    "        print(i, end='')\n",
    "        dog_total += predict_path(model, f'./PetImages/Dog/{i}.jpg')\n",
    "        cat_total += predict_path(model, f'./PetImages/Cat/{i}.jpg')\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Dog Mean: {(dog_total/num_images):.4f}\\t Cat Mean: {(cat_total/num_images):.4f}')\n",
    "\n",
    "# predict_model(model)\n",
    "predict_path(model, './PetImages/Cat/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(training_data, steps=20000 // 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMVJ-41HsOcF"
   },
   "source": [
    "# Save Final Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVhhg6KkqjB8"
   },
   "outputs": [],
   "source": [
    "print(\"Compressing Files...\")\n",
    "!zip \"$(date)-hdf5.zip\" *.hdf5\n",
    "\n",
    "print(\"Cleaning Up...\")\n",
    "!rm *.hdf5\n",
    "\n",
    "print(\"Done!\")\n",
    "!bash -c \"du -h *-hdf5.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Cats and Dogs.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
